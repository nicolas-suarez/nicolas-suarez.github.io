[{"authors":["admin"],"categories":null,"content":"","date":1616025600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1616025600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Nicolás Suárez Chavarría","type":"authors"},{"authors":["Nina Prakash","Nicolás Suárez Chavarría","Andrea Vallebueno"],"categories":null,"content":"This was our class project for Stanford CS230 \u0026ldquo;Deep Learning\u0026rdquo; class during the Winter 2021 quarter. The project was featured as one of the Outstanding projects for the Winter 2021 quarter. You can find our final report here.\nDescription This project examines the relationship between the level of ozone concentration in urban locations and their physical features through the use of Convolutional Neural Networks (CNNs). We train two models, including one trained on satellite imagery (\u0026ldquo;Satellite CNN\u0026rdquo;) to capture higher-level features such as the location\u0026rsquo;s geography, and the other trained on street-level imagery (\u0026ldquo;Street CNN\u0026rdquo;) to learn ground-level features such as motor vehicle activity. These features are then concatenated to train neural network (\u0026ldquo;Concat NN\u0026rdquo;) on this shared representation and predict the location\u0026rsquo;s level of ozone as measured in parts per billion.\nData We obtained ozone measurements (parts per billion) for 12,976 semi-unique locations with ozone levels information mostly located in North America from AirNow.\nOur satellite imagery dataset was constructed using the Google Earth Engine API: for each location labeled with an ozone reading, we retrieve one satellite image centered at that location from the Landsat 8 Surface Reflectance Tier 1 Collection with a resolution of 224 $\\times$ 224 pixels which represents $6.72$ km $\\times$ $6.72$ km. We use 7 bands from this collection: RGB, ultra blue, near infrared, and two shortwave infrared bands. We preprocess each of our images by adding a cloud mask per pixel and then computing the per pixel and band mean composite of all the available images for the year 2020.\nThe street-level imagery dataset was constructed using the Google Maps Street View API. For each location labeled with an ozone level, we randomly sample 10 geospatial points within $6.72$ km from the measurement point.\nHere we can see some examples from our dataset:\nNetwork architecture We train the two CNNs separately on the satellite and street-level imagery, both using a ResNet-18 architecture implemented in PyTorch and pretrained on the ImageNet dataset. The models are trained separately as the nature of the features they need to learn to associate with ozone concentration is quite different for each dataset. Transfer learning is used for both CNNs to leverage lower-level features learned on the ImageNet dataset. The ResNet-18 architecture was slightly adapted for our particular task; in the case of the satellite imagery, the CNN\u0026rsquo;s input layer was modified to accommodate for the image\u0026rsquo;s seven channels and was initialized using Kaiming initialization.\nAfter training both CNNs separately to predict the ozone reading for each location, we extract $512$ features for each satellite and each street image. These are concatenated to create a feature vector of size $1,024$ representing the satellite image and a particular street view of a given location. We then train a Concatenated Feedforward Neural Network (NN) using these multiple representations of each location to predict the location\u0026rsquo;s average ozone level in 2020.\nMore details about regularization, the tuning process of hyperparameters and training of the network can be found in the report.\nResults After tuning our hyperparameters and training our models, we obtain the following performance (Root Mean Square Error in our test set):\n    Satellite Model Street-level Model Concatenated Model     Test RMSE (ppb) 12.48 20.64 11.70    We can also visually compare our predictions for the test with ground truth values in the following figure:\n  ","date":1616025600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616025600,"objectID":"2ec6b6e0f5a1e75b5ffe010472990139","permalink":"https://nicolas-suarez.github.io/research/urban-emissions/","publishdate":"2021-03-18T00:00:00Z","relpermalink":"/research/urban-emissions/","section":"research","summary":"Understanding the impact of the built environment and urban populations on climate change and air quality is a growing challenge as the percentage of the world's population that resides in urban areas continues to rise. In particular, human activity levels have been shown to be directly linked with ground-level ozone, which is responsible for several health and climate effects. We explore this relationship through the use of a multimodal learning architecture that predicts ozone concentrations (parts per billion) in urban areas from satellite and street-level imagery. The model comprises two Convolutional Neural Networks (CNN), one trained on satellite images of each location to learn higher-level features such as geographical characteristics and land use, and another trained on multiple street-level images of each location to learn ground-level features such as motor vehicle activity. The feature representations learned from each sub-model are concatenated and passed through several fully connected layers to predict the ozone level of the location. This concatenated model achieves a test RMSE of 11.70 ppb. This approach can be used to inform urban planning and policy by providing an insight into the particular urban features that aggravate ozone concentrations.","tags":["Working Papers"],"title":"Predicting Ground Level Ozone Concentration from Urban Satellite and Street Level Imagery using Multimodal CNN","type":"research"},{"authors":["Nicolás Suárez Chavarría"],"categories":[],"content":"I usually prefer to work in LaTeX, but from time to time I\u0026rsquo;m forced to share my results in Excel. In Stata, I used to use the Outreg2 command, but the output generated by this program has a weird format, and you always have to read some error messages in Excel.\nBecause of this, I decided to program a little piece of code to easily export my regression results to Excel. I\u0026rsquo;m not very creative, so I called my custom command export_tables. You can find the code at my Github page.\nSyntax export_tables, Models(string) Dec(real) Cell(string) USING(string) SHEET(string) [ Options ]\r Where:\n Models() contains a list of the models you estimated, and saved with the \u0026ldquo;Estimates Store\u0026rdquo; command. Dec() indicates the number of decimal places of your model\u0026rsquo;s coefficients. Cell() indicates in which Excel\u0026rsquo;s cell the table is going to begin. Using() indicates where are you going to save the excel document, and Sheet() indicates how the sheet of the document will be named. In options, you can use Keep() to keep the coefficients associated with certain variables, Drop() to drop the coefficients associated with some variables, Stats() to report some e() statistics stored in your models and Dstats() helps you to set the number of decimal places associated with these statistics. Variables prints the name of the variables in your table, and label prints the variables' labels instead. Std to display standard errors below the coefficients, Pvalues to display the p-values of the coefficients below them, and See to print your output in the console as a table.  How to use the command The idea behind the command is to run your regressions, store the results with estimates store, and then export the results to excel. You will get a table without a header, but you will see in every row the name of the variable, the coefficients of each model (with stars representing the significance level), the standard errors, and at the end, some statitics. After running this command, you can use putexcel to further modify your spreadsheet, adding headers, bold or italic text, borders, etc.\nFor the moment, this command only works with regression commands like reg, probit, ivreg2 or others, but doesn\u0026rsquo;t work with commands like heckman or others that display the results of 2 or more estimations at the same time.\nExample You can run the following example code:\nsysuse auto\rreg mpg rep78 trunk\rest sto m1\rreg turn length gear_ratio rep78\rest sto m2\rexport_tables, models(m1 m2) dec(2) cell(A1) using(\u0026quot;test.xlsx\u0026quot;) sheet(\u0026quot;sheet1\u0026quot;) stats(\u0026quot;N r2_a\u0026quot;) label std see\r You could also use a wilcard in the models, and write something like models(m*).\n","date":1555545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555545600,"objectID":"addee16a8f767222042cb01faada6a3f","permalink":"https://nicolas-suarez.github.io/blog/stata-tables/","publishdate":"2019-04-18T00:00:00Z","relpermalink":"/blog/stata-tables/","section":"blog","summary":"A Stata ADO file to export tables to Excel without the problems of Outreg2","tags":[],"title":"A little Stata command to export tables to Excel","type":"blog"},{"authors":["Dante Contreras","Gabriel Otero","Juan Díaz","Nicolás Suárez"],"categories":null,"content":"","date":1551398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551398400,"objectID":"d1edaba4fc000f3521fd8cb8bbb4367e","permalink":"https://nicolas-suarez.github.io/research/social-networks/","publishdate":"2019-03-01T00:00:00Z","relpermalink":"/research/social-networks/","section":"research","summary":"Long-standing literature argues that social capital is closely implicated in labour market outcomes. However, this hypothesis has yet to be tested in Latin America, the most unequal region in the world. We focus on Chile, one of the most stratified countries in Latin America. This study examines the relationship between social capital and four measures of status attainment, including job prestige and employment income. We use data from the first wave of the Longitudinal Social Study of Chile (ELSOC), a representative survey of the Chilean urban population aged 18–75 years. We analyse a subsample of 1,351 individuals who are currently employed. A Bayesian model of over-dispersion with relational data is used to estimate the size of the network, a novel measure of social capital. We analyse the data set using linear and logistic regression models and a complementary path analysis, first estimating models for the entire sample, and then splitting the sample into three groups to evaluate differences within individuals’ socioeconomic background. Results indicate that contacts’ occupational prestige has a positive association with job prestige and employment income, while the size of the network increases individuals’ salaries and labour participation. We also observe that social capital flows through stratified networks which tend to favour individuals from high socioeconomic backgrounds. We discuss the need to conduct more in-depth evaluations of how better creation of social capital and its effects on status attainment could be closely linked to positions of privilege and advantage accumulation processes in highly unequal contexts.","tags":["Published"],"title":"Inequality in social capital in Chile: Assessing the importance of network size and contacts’ occupational prestige on status attainment","type":"research"},{"authors":["Nicolás Suárez Chavarría"],"categories":null,"content":"","date":1543363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543363200,"objectID":"d992229d76fc5e8023cc6cf47d419381","permalink":"https://nicolas-suarez.github.io/research/commuting-time/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/research/commuting-time/","section":"research","summary":"Taking advantage of georeferenced data from Chilean students, we estimate the impact of commuting time over academic achievement. As the commuting time is an endogenous variable, we use instrumental variables and fixed effects at school level to overcome this problem. Also, as we don't know which mode of transport the students use, we complement our analysis using machine learning methods  to predict the transportation mode. Our findings suggest that the commuting time has a negative effect over academic performance, but this effect is not always significant.","tags":["Working Papers"],"title":"The impact of commuting time over educational achievement: A machine learning approach","type":"research"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://nicolas-suarez.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]