[{"authors":["admin"],"categories":null,"content":"","date":1622764800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1622764800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Nicolás Suárez Chavarría","type":"authors"},{"authors":["Nicolás Suárez Chavarría"],"categories":null,"content":"Description This is my final project for Stanford\u0026rsquo;s ECON 293: Machine Learning and Causal Inference for the Spring 2021 quarter. The code used for this project (in RMarkDown) can be found here and a write up explaining the project more in detail is available here.\nIn this project revisit the findings of Michalopoulos, S., \u0026amp; Papaioannou, E. (2014). National institutions and subnational development in Africa. The Quarterly journal of economics, 129(1), 151-213.. In the mentioned article, the authors explore the role of national institutions on local development levels for in Africa. They exploit the fact that the national boundaries of African countries drawn during their independence partitioned more than 200 ethnic groups across adjacent countries, so within the territory of an ethnic group we have individuals subjected to similar cultures, residing in homogeneous geographic areas, but that are exposed to different national institutions.\nWe can use a Geographical regression discontinuity design (as the authors do in Section IV.C of their paper) to see the effect of exposure to different levels of institutions over local development levels, measured with satellite images of light density at night, and using as a running variable the distance to the national border partitioning a ethnicity.\nThe authors use 3rd and 4th degree RD polynomials, define the bandwidth of their RD design in arbitrary ways, and there are some pixels were the distance to the border is not computed properly, so to overcome those flaws and check how robust their findings are, I plan to use the optrdd package from Imbens, G., \u0026amp; Wager, S. (2019). Optimized regression discontinuity designs. Review of Economics and Statistics, 101(2), 264-278. to estimate an Optimized Regression Discontinuity model, a data-driven model that doesn\u0026rsquo;t rely on polynomial or bandwidth definition.\nEmpirical design Before diving into the issues with the dataset, I will first explain the empirical design for this project. Here, our unit of analysis are patches of 12.6 by 12.6 km of land in Africa. Our dependent variable is a dummy indicating if a pixel is lit or not, according to 2007-2008 satellite night lights measures. Our treatment variable is a dummy indicating if a pixel is on the side of the ethnic tribe territory with higher national institutions (measured as either Rule of Law or Control of Corruption).\nBesides that main variables, the authors also control for population density in their original article, and they also have information about the country and tribe where a pixel is located, and some information related to its geography, like elevation, presence of water, a malaria index, and similar stuff.\nData sources I obtained the original pixel-level dataset from Stelios Michalopoulos' website. I obtained the shapefiles for the ethnic tribes from Nathan Nunn\u0026rsquo;s website. The shapefile with the grid of pixels covering Africa was provided directly by Stelios Michalopoulos.\nProblems with the current data In the current dataset downloaded from the authors website, there are some problems with how the distance to the border is calculated, and they are also missing a lot of pixels, since they discarded all uninhabited pixels. We can illustrate these problems by looking at the Bideyat tribe, located in the border shared among Egypt, Sudan, Chad and Libya. Most of the pixels are in Sudan and Chad, so the authors considered only those 2 countries for their analysis.\nIn following figure we are going to plot the distance to the border for the pixels in Chad (left) and Sudan (right), where blue pixels are the closest, and yellow are the farthest from the national border. Here we can observe that the distance to the border is clearly calculated in the wrong way: we have around 10 pixels at the top of Sudan, in the frontier with Egypt, that are marked to be less than 50 km to the border between Sudan and Chad, but they are around 200 kilometers away from the mentioned border. Their distance to the border was very likely computed around the wrong border.\n  As mentioned before, another problem present in this dataset is that there are a lot of missing pixels: in our previous figure we can see a lot of areas with very little pixels. If we check how many pixels we have per country in the Bideyat territory: there are 598 pixels in Sudan, but only 38 pixels in Chad, and we even have 45 pixels in Egypt, a country that should not be considered here given the approach of the authors.\nThe imbalance present here could be quite problematic, because we have relatively very little pixels in Chad compared to Sudan, and also because the pixels in Chad are not very close to the border, so a regression discontinuity analysis is not going to produce interesting results here.\nReplicating and fixing the dataset Given the previous problems, before trying to estimate causal effects, I\u0026rsquo;m going to rebuild from scratch the dataset, fixing some issues and expanding the number of units in our sample. I will do the following:\n I\u0026rsquo;m going to start by loading the original grid of pixels for Africa. To that grid I will add information about nightlights (average of the DMSP OLS for the years 2007 and 2008) and population density (Population density in 2000). After that, I will also used GIS methods to identify in which country and tribe is every pixel located. With that information, and to use a similar sample to the original one, for each partitioned tribe, I will compute the distance to the national border. To follow Michalopoulos \u0026amp; Papaioannou (2014), I will only consider the two biggest countries in term of area inside a tribe if there are more than 2 countries in the partitioned territory. Finally, using the country and tribe names, I will recover the Rule of Law and Control of Corruption treatment variables from the original dataset, as well as the clustering variable (variable used by the authors and defined in the original ethnographic Atlas of Murdock that groups similar tribes into bigger groups).  With this procedure we pass from an original sample with 40,209 observations, to a new sample with valid information for 55,055 observations. To check that we did everything properly when rebuilding the dataset, in next figure we can see again the distance to the border for the Bideyat tribe, but for the new dataset. We can see that we have data for all pixels in both Chad and Sudan, and that the distance to the border is now computed with respect to the right border.\n  Comparing the different samples I also replicate the original results of estimating equation (3) of Michalopoulos \u0026amp; Papaioannou (2014), that are displayed in their Table VI. To keep things short, those results are only available in the write-up and the knitted version of the RMarkDown code.\nUnivariate Optimized RDD Now that we checked that our new sample is almost identical to the original sample, we can use our optimized RDD methodology on it. In this section I will use the univariate version of the optimized RDD method, estimating a model where the univariate running variable is the distance of the pixels to the national border. We previously computed the distance to the border, and I now modified that variable so the distance is negative for the pixels on the side of the border with lower Rule of Law or Control of Corruption.An advantage of doing this analysis first is that since we use the same running variable as the original paper, we should obtain comparable results, or at least more similar results than when we change to a multivariate running variable.\nTo compute the curvature bound $B$ in this univariate case, we will follow Imbens and Wager (2019) and fit a global quadratic model for both treated and control samples. We get the absolute values of the coefficients, and then we keep as our curvature bound the maximum between the 2 quadratic coefficients. In this application there might be significant heterogeneity in the curvature between tribes, so I will also estimate the curvature within every tribe. I will discard the NA and 0 values obtained for the curvature bound, and then these values are going to be used for a sensitivity analysis. Specifically, for each treatment variable (high Rule of Law or high Control of Corruption) I will estimate the effect of institutions over local development using distance to the border as my running variable, and using the optrdd package. I set the estimation point at 0 (the national border within every tribe). I will do this for 50 values of our curvature bound $B$, ranging from the minimum to the maximum of the within tribe curvatures computed with the global quadratic model. For each model, besides recovering the treatment effect, we also obtain a 95% confidence interval.\nIn the 2 next figures we can see the results of these sensitivity analysis: we can notice that for both of our institutional quality treatment variables the confidence intervals contain 0, so neither of them is statistically significant for most of the values of $B$.\n    We can also plot our weights to see how they look for a particular tribe (given the number of tribes, looking at all the tribes simultaneously is not feasible). To do this, I will estimate the model using the Rule of Law treatment variable, and for the curvature bound $B$ I use the curvature obtained when we use the global fit model for all the sample. In the following figure we can see the weights for the Azjer tribe, and we can notice that the weights for this tribe look a little weird. For the pixels in Libya there is a clear gradient, and the biggest weights are towards the border, whereas the weights in Algeria look weird, giving a lot of weight to pixels in the center of the partition, but not in the border.\n  Multivariate Optimized RDD Now we will proceed to estimate a multivariate optimized RDD. We are going to estimate constant treatment effects, and we will use the latitude and longitude of the centroids of the pixels as the running variables.\nTo estimate the curvature bound $B$, I\u0026rsquo;m going to follow the code from the geographic RDD example in Imbens and Wager (2019). Here I will use a slightly modified version of their get_curvature function, used to ran a cross-validated ridge regression with interacted 7th-order natural splines as features in each side of the border, and then use this to get a worst-case local curvature. Here I apply the function to the whole sample for both of the treatment variables, and I don\u0026rsquo;t estimate individual curvatures for the different tribes, since a lot of them have too little observations to produce reliable results with a technique like this.\nWith this function, we can proceed to estimate our multivariate optimized RDD: for each treatment variable (high Rule of Law or high Control of Corruption) I will estimate the effect of institutions over local development using the latitude and longitude of my pixels as my running variables. I will do this for 20 values of our curvature bound, between $0.1B$ and $10B$, where the original curvature $B$ is computed with the get_curvature function separately for each of the treatment variables. For each model, besides recovering the treatment effect, we also obtain a 95% confidence interval.\nIn the two following figures we can see the results of these sensitivity analysis: we can notice that for Rule of Law generates a positive and mostly statistically significant effect, but when our treatment is defined by Control of Corruption the effect becomes not statistically significant.\n    Finally, we can also plot our weights to see how they look for a particular tribe. To do this, I will estimate the model using the Rule of Law treatment variable with maximum curvature $B$. In the next figure we can look again at the weights for the Azjer tribe, and in this case the pixels look a little weird, since there is not a clear gradient towards the border. I believe this is because this method might not work with multiple geographies at the same time, since there is nothing preventing the program to compare pixels among tribes and ignore the tribe borders.\n  Concluding remarks In this project I revisited the findings of Michalopoulos \u0026amp; Papaioannou (2014). I started by fixing some problems with their data, and then replicating their results with the new data to see if the replication was working properly. Using their methodology I found no statistically significant effect of institutions over local development in any of the samples.\nAfter that, I applied the Optimized Regression Discontinuity Design method with an univariate running variable, the distance to the border, using a wide range of curvature bounds $B$ derived from a within-tribe curvature analysis. Again I found no statistically significant effect.\nFinally, I applied the Optimized Regression Discontinuity Design method with an multivariate running variable, the latitude and longitude of pixels, and I derived the curvature bound using the non-parametric global method described in Imbens and Wager (2019). This time around I found that there is a positive and statistically significant effect of national institutions over development when we define institutions as Rule of Law, but that effect disappears when we measure institutions with Control of Corruption. These last findings are very relevant, since they challenge the previous evidence regarding this topic.\nHowever, I interpret these results with caution: I\u0026rsquo;m not fully sure of how well the multivariate running variable RDD method works here, since we are analyzing several geographical units at the same time, but the model doesn\u0026rsquo;t explicitly defines in which tribe a pixel is. This could lead to comparisons of pixels among different tribes, and the optimization process could end up ignoring completely the national borders that split tribes. There is more work to be done here to adapt this method to this geographical setting with multiple units, maybe related to re-centering the coordinates of each pixel, or adding more explicit constraints into the optimization problem.\nAnother possible point to improve is the curvature bound $B$ for the multivariate case: I ended up estimating just 1 bound, so it would be very interesting to develop methods to estimate the curvature bound in a way that it takes into account the local curvatures for each tribe.\n","date":1622764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622764800,"objectID":"7904e50a2b0d801e64ef19f1c177ebe2","permalink":"https://nicolas-suarez.github.io/research/opt-rdd/","publishdate":"2021-06-04T00:00:00Z","relpermalink":"/research/opt-rdd/","section":"research","summary":"In this project I revisit the findings of Michalopoulos \u0026 Papaioannou (2014), exploring the role of national institutions on local development levels in Africa. The authors use 3rd and 4th degree RD polynomials, define the bandwidth of their RD design in arbitrary ways, and there are some pixels were the distance to the border is not computed properly, so to overcome those flaws and check how robust their findings are, I plan to use the optrdd package from Imbens \u0026 Wager (2019) to estimate an Optimized Regression Discontinuity model, a data-driven model that doesn’t rely on polynomial or bandwidth definitions.","tags":["Working Papers","Machine Learning"],"title":"Optimized Regression Discontinuity Application: the effect of national institutions over local development","type":"research"},{"authors":["Nina Prakash","Nicolás Suárez Chavarría","Andrea Vallebueno"],"categories":null,"content":"This was our class project for Stanford CS230 \u0026ldquo;Deep Learning\u0026rdquo; class during the Winter 2021 quarter. The project was featured as one of the Outstanding projects for the Winter 2021 quarter. You can find our final report here.\nDescription This project examines the relationship between the level of ozone concentration in urban locations and their physical features through the use of Convolutional Neural Networks (CNNs). We train two models, including one trained on satellite imagery (\u0026ldquo;Satellite CNN\u0026rdquo;) to capture higher-level features such as the location\u0026rsquo;s geography, and the other trained on street-level imagery (\u0026ldquo;Street CNN\u0026rdquo;) to learn ground-level features such as motor vehicle activity. These features are then concatenated to train neural network (\u0026ldquo;Concat NN\u0026rdquo;) on this shared representation and predict the location\u0026rsquo;s level of ozone as measured in parts per billion.\nData We obtained ozone measurements (parts per billion) for 12,976 semi-unique locations with ozone levels information mostly located in North America from AirNow.\nOur satellite imagery dataset was constructed using the Google Earth Engine API: for each location labeled with an ozone reading, we retrieve one satellite image centered at that location from the Landsat 8 Surface Reflectance Tier 1 Collection with a resolution of 224 $\\times$ 224 pixels which represents 6.72 km $\\times$ 6.72 km. We use 7 bands from this collection: RGB, ultra blue, near infrared, and two shortwave infrared bands. We preprocess each of our images by adding a cloud mask per pixel and then computing the per pixel and band mean composite of all the available images for the year 2020.\nThe street-level imagery dataset was constructed using the Google Maps Street View API. For each location labeled with an ozone level, we randomly sample 10 geospatial points within 6.72 km from the measurement point.\nHere we can see some examples from our dataset:\n  Network architecture We train the two CNNs separately on the satellite and street-level imagery, both using a ResNet-18 architecture implemented in PyTorch and pretrained on the ImageNet dataset. The models are trained separately as the nature of the features they need to learn to associate with ozone concentration is quite different for each dataset. Transfer learning is used for both CNNs to leverage lower-level features learned on the ImageNet dataset. The ResNet-18 architecture was slightly adapted for our particular task; in the case of the satellite imagery, the CNN\u0026rsquo;s input layer was modified to accommodate for the image\u0026rsquo;s seven channels and was initialized using Kaiming initialization.\nAfter training both CNNs separately to predict the ozone reading for each location, we extract 512 features for each satellite and each street image. These are concatenated to create a feature vector of size 1,024 representing the satellite image and a particular street view of a given location. We then train a Concatenated Feedforward Neural Network (NN) using these multiple representations of each location to predict the location\u0026rsquo;s average ozone level in 2020.\n  More details about regularization, the tuning process of hyperparameters and training of the network can be found in the report.\nResults After tuning our hyperparameters and training our models, we obtain the following performance (Root Mean Square Error in our test set):\n    Satellite Model Street-level Model Concatenated Model     Test RMSE (ppb) 12.48 20.64 11.70    We can also visually compare our predictions for the test with ground truth values in the following figure:\n  ","date":1616025600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616025600,"objectID":"2ec6b6e0f5a1e75b5ffe010472990139","permalink":"https://nicolas-suarez.github.io/research/urban-emissions/","publishdate":"2021-03-18T00:00:00Z","relpermalink":"/research/urban-emissions/","section":"research","summary":"Understanding the impact of the built environment and urban populations on climate change and air quality is a growing challenge as the percentage of the world's population that resides in urban areas continues to rise. In particular, human activity levels have been shown to be directly linked with ground-level ozone, which is responsible for several health and climate effects. We explore this relationship through the use of a multimodal learning architecture that predicts ozone concentrations (parts per billion) in urban areas from satellite and street-level imagery. The model comprises two Convolutional Neural Networks (CNN), one trained on satellite images of each location to learn higher-level features such as geographical characteristics and land use, and another trained on multiple street-level images of each location to learn ground-level features such as motor vehicle activity. The feature representations learned from each sub-model are concatenated and passed through several fully connected layers to predict the ozone level of the location. This concatenated model achieves a test RMSE of 11.70 ppb. This approach can be used to inform urban planning and policy by providing an insight into the particular urban features that aggravate ozone concentrations.","tags":["Working Papers","Machine Learning"],"title":"Predicting Ground Level Ozone Concentration from Urban Satellite and Street Level Imagery using Multimodal CNN","type":"research"},{"authors":["Nicolás Suárez Chavarría"],"categories":[],"content":"I usually prefer to work in LaTeX, but from time to time I\u0026rsquo;m forced to share my results in Excel. In Stata, I used to use the Outreg2 command, but the output generated by this program has a weird format, and you always have to read some error messages in Excel.\nBecause of this, I decided to program a little piece of code to easily export my regression results to Excel. I\u0026rsquo;m not very creative, so I called my custom command export_tables. You can find the code at my Github page.\nSyntax export_tables, Models(string) Dec(real) Cell(string) USING(string) SHEET(string) [ Options ]\r Where:\n Models() contains a list of the models you estimated, and saved with the \u0026ldquo;Estimates Store\u0026rdquo; command. Dec() indicates the number of decimal places of your model\u0026rsquo;s coefficients. Cell() indicates in which Excel\u0026rsquo;s cell the table is going to begin. Using() indicates where are you going to save the excel document, and Sheet() indicates how the sheet of the document will be named. In options, you can use Keep() to keep the coefficients associated with certain variables, Drop() to drop the coefficients associated with some variables, Stats() to report some e() statistics stored in your models and Dstats() helps you to set the number of decimal places associated with these statistics. Variables prints the name of the variables in your table, and label prints the variables' labels instead. Std to display standard errors below the coefficients, Pvalues to display the p-values of the coefficients below them, and See to print your output in the console as a table.  How to use the command The idea behind the command is to run your regressions, store the results with estimates store, and then export the results to excel. You will get a table without a header, but you will see in every row the name of the variable, the coefficients of each model (with stars representing the significance level), the standard errors, and at the end, some statitics. After running this command, you can use putexcel to further modify your spreadsheet, adding headers, bold or italic text, borders, etc.\nFor the moment, this command only works with regression commands like reg, probit, ivreg2 or others, but doesn\u0026rsquo;t work with commands like heckman or others that display the results of 2 or more estimations at the same time.\nExample You can run the following example code:\nsysuse auto\rreg mpg rep78 trunk\rest sto m1\rreg turn length gear_ratio rep78\rest sto m2\rexport_tables, models(m1 m2) dec(2) cell(A1) using(\u0026quot;test.xlsx\u0026quot;) sheet(\u0026quot;sheet1\u0026quot;) stats(\u0026quot;N r2_a\u0026quot;) label std see\r You could also use a wilcard in the models, and write something like models(m*).\n","date":1555545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555545600,"objectID":"addee16a8f767222042cb01faada6a3f","permalink":"https://nicolas-suarez.github.io/blog/stata-tables/","publishdate":"2019-04-18T00:00:00Z","relpermalink":"/blog/stata-tables/","section":"blog","summary":"A Stata ADO file to export tables to Excel without the problems of Outreg2","tags":[],"title":"A little Stata command to export tables to Excel","type":"blog"},{"authors":["Dante Contreras","Gabriel Otero","Juan Díaz","Nicolás Suárez"],"categories":null,"content":"","date":1551398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551398400,"objectID":"d1edaba4fc000f3521fd8cb8bbb4367e","permalink":"https://nicolas-suarez.github.io/research/social-networks/","publishdate":"2019-03-01T00:00:00Z","relpermalink":"/research/social-networks/","section":"research","summary":"Long-standing literature argues that social capital is closely implicated in labour market outcomes. However, this hypothesis has yet to be tested in Latin America, the most unequal region in the world. We focus on Chile, one of the most stratified countries in Latin America. This study examines the relationship between social capital and four measures of status attainment, including job prestige and employment income. We use data from the first wave of the Longitudinal Social Study of Chile (ELSOC), a representative survey of the Chilean urban population aged 18–75 years. We analyse a subsample of 1,351 individuals who are currently employed. A Bayesian model of over-dispersion with relational data is used to estimate the size of the network, a novel measure of social capital. We analyse the data set using linear and logistic regression models and a complementary path analysis, first estimating models for the entire sample, and then splitting the sample into three groups to evaluate differences within individuals’ socioeconomic background. Results indicate that contacts’ occupational prestige has a positive association with job prestige and employment income, while the size of the network increases individuals’ salaries and labour participation. We also observe that social capital flows through stratified networks which tend to favour individuals from high socioeconomic backgrounds. We discuss the need to conduct more in-depth evaluations of how better creation of social capital and its effects on status attainment could be closely linked to positions of privilege and advantage accumulation processes in highly unequal contexts.","tags":["Published"],"title":"Inequality in social capital in Chile: Assessing the importance of network size and contacts’ occupational prestige on status attainment","type":"research"},{"authors":["Nicolás Suárez Chavarría"],"categories":null,"content":"","date":1543363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543363200,"objectID":"d992229d76fc5e8023cc6cf47d419381","permalink":"https://nicolas-suarez.github.io/research/commuting-time/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/research/commuting-time/","section":"research","summary":"Taking advantage of georeferenced data from Chilean students, we estimate the impact of commuting time over academic achievement. As the commuting time is an endogenous variable, we use instrumental variables and fixed effects at school level to overcome this problem. Also, as we don't know which mode of transport the students use, we complement our analysis using machine learning methods  to predict the transportation mode. Our findings suggest that the commuting time has a negative effect over academic performance, but this effect is not always significant.","tags":["Working Papers"],"title":"The impact of commuting time over educational achievement: A machine learning approach","type":"research"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://nicolas-suarez.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]