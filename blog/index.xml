<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog Posts | Nicolás Suárez Chavarría</title>
    <link>https://nicolas-suarez.github.io/blog/</link>
      <atom:link href="https://nicolas-suarez.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    <description>Blog Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 25 Mar 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://nicolas-suarez.github.io/media/icon_hu5c88e8a9398cf657f3e83a0d9ccab3ac_75464_512x512_fill_lanczos_center_3.png</url>
      <title>Blog Posts</title>
      <link>https://nicolas-suarez.github.io/blog/</link>
    </image>
    
    <item>
      <title>Generalized 2SLS implementation in Stata</title>
      <link>https://nicolas-suarez.github.io/blog/peer_iv/</link>
      <pubDate>Fri, 25 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://nicolas-suarez.github.io/blog/peer_iv/</guid>
      <description>&lt;p&gt;For one of my research projects I was working on peer effects for college students, and I wanted to use the Generalized 2SLS procedure to estimate peer effects described in &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0304407609000335&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bramoullé, Y., Djebbari, H., &amp;amp; Fortin, B. (2009). Identification of peer effects through social networks. Journal of econometrics, 150(1), 41-55.&lt;/a&gt;. The problem is that this project required a lot of data work and cleaning, so I worked on it on Stata mostly, but there is not a lot of support for peer effects regressions on &lt;code&gt;Stata&lt;/code&gt;, so I had to adapt the code of Bramoullé et al. (2009) on my own. I based my code on their article, and on the code shared on 
&lt;a href=&#34;https://rpubs.com/Nicolas_Gallo/549370&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Habiba Djebbari&amp;rsquo;s website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here I share my code, some examples about how to use it, and a comparison of my code and the original &lt;code&gt;R&lt;/code&gt; code used by the authors.&lt;/p&gt;
&lt;p&gt;To wrote this, I took advantage of Stata&amp;rsquo;s new integration with Python and Jupyter Notebooks (more information on how to use this feature can be found &lt;a href=&#34;https://www.stata.com/new-in-stata/jupyter-notebooks/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;). I also used the &lt;a href=&#34;https://rpy2.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;rpy2 package&lt;/a&gt; to run &lt;code&gt;R&lt;/code&gt; commands inside a Jupyter notebook.&lt;/p&gt;
&lt;p&gt;The original Jupyter Notebook I wrote for this can be found in my &lt;a href=&#34;https://github.com/nicolas-suarez/peer_iv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Github repository&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;setting-up-stata-in-python&#34;&gt;Setting up Stata in Python&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#setting up Stata in Python
import stata_setup
stata_setup.config(&amp;quot;C:/Program Files/Stata17&amp;quot;, &amp;quot;mp&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;  ___  ____  ____  ____  ____ ®
 /__    /   ____/   /   ____/      17.0
___/   /   /___/   /   /___/       MP—Parallel Edition

 Statistics and Data Science       Copyright 1985-2021 StataCorp LLC
                                   StataCorp
                                   4905 Lakeway Drive
                                   College Station, Texas 77845 USA
                                   800-STATA-PC        https://www.stata.com
                                   979-696-4600        stata@stata.com

Stata license: Unlimited-user 4-core network, expiring 21 Jul 2022
Serial number: xxxxxxxxxxxx
  Licensed to: Nicolas Suarez
               Stanford University

Notes:
      1. Unicode is supported; see help unicode_advice.
      2. More than 2 billion observations are allowed; see help obs_advice.
      3. Maximum number of variables is set to 5,000; see help set_maxvar.

Running C:\Program Files\Stata17/profile.do ...
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;peer-iv-function&#34;&gt;Peer IV function&lt;/h1&gt;
&lt;p&gt;To implement linear in means regressions, I wrote the &lt;code&gt;peer_iv&lt;/code&gt; function. This function takes as inputs, as any other regression function, a dependent variable and independent variables, plus an adjacency matrix &lt;code&gt;G&lt;/code&gt; to perform the calculations. This matrix has to be a &lt;code&gt;Mata&lt;/code&gt; matrix object (&lt;code&gt;Stata&lt;/code&gt; matrices have size limitations). The option &lt;code&gt;row&lt;/code&gt; allows us to row-normalize the adjacency matrix (so the sum of each row is 1, and we can interpret the product of a variable and the matrix as weighted means), and the &lt;code&gt;fixed&lt;/code&gt; option adds group level fixed effects.&lt;/p&gt;
&lt;p&gt;The matrix generates an standard Stata regression output, containing coefficients, standard errors, p-values and all the relevant information, and it stores eclass results. This means that the output could be stored with custom commands like &lt;code&gt;outreg2&lt;/code&gt;, &lt;code&gt;estout&lt;/code&gt; or &lt;code&gt;esttab&lt;/code&gt; that allow the user to build customizable output tables.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;%%stata

capture program drop peer_iv
program define peer_iv, eclass
version 17
syntax varlist, ADJacency(name) [ROW FIXED OLS] 
/* implements the generalized 2SLS model of Bramoulle et al (2009), without fixed effects.
The model includes a constant, then the endogenous effect, effects of the independent variables, and then the exogenous effects.
For more details see https://rpubs.com/Nicolas_Gallo/549370

INPUTS:
varlist = exogenous variables
dep= dependent variable
adjacency=name of the adjacency matrix in Mata
row=optional, row normalizes the adjacency matrix
fixed=optional, estimates model with cohort level fixed effects
ols=optional, OLS results. Don&#39;t use together with FIXED

OUTPUT:
displays the coefficients and standard errors in a table. Stores eclass results.
*/

*separating dependent from independent variables
gettoken dep varlist: varlist
preserve
quietly{
*checking if there are missing values in our data
reg `dep&#39; `varlist&#39;
*recovering the indexes of non-missing observations
gen muestra=e(sample)
ereturn clear 

*moving data as matrices
mata X=st_data(.,&amp;quot;`varlist&#39;&amp;quot;)
mata y=st_data(.,&amp;quot;`dep&#39;&amp;quot;)
mata muestra=st_data(.,&amp;quot;muestra&amp;quot;)

*dropping missing values from data matrices
mata X=select(X,muestra)
mata y=select(y,muestra)

*dropping missing values from G matrix (eliminating the rows and columns with missing values, so the matrix are comformable)
mata G1=select(`adjacency&#39;,muestra)
mata G1=select(G1,muestra&#39;)

*row normalizing G if needed
if &amp;quot;`row&#39;&amp;quot;!=&amp;quot;&amp;quot; mata G1=G1:/editvalue(rowsum(G1),0,1)

*generating identity matrix
mata Id=I(rows(G1))

*OLS results
if &amp;quot;`ols&#39;&amp;quot;!=&amp;quot;&amp;quot; {
    mata X_1 =  J(rows(X),1,1), G1*y, X, G1*X 
    mata theta= invsym(quadcross(X_1, X_1))*quadcross(X_1, y)
    mata e= y - X_1*theta
    mata V = (quadsum(e:^2)/(rows(X_1)-cols(X_1)))*invsym(quadcross(X_1, X_1))
}
else {
    *putting matrices together
    *with fixed effects
    if &amp;quot;`fixed&#39;&amp;quot;!=&amp;quot;&amp;quot; {
        mata S=( (Id-G1)*X, (Id-G1)*G1*X, (Id-G1)*G1*G1*X )
        mata X_1= ( (Id-G1)*G1*y, (Id-G1)*X, (Id-G1)*G1*X )             
    }
    else{
        mata S=( J(rows(X),1,1), X, G1*X, G1*G1*X )
        mata X_1= ( J(rows(X),1,1), G1*y, X, G1*X )
    }
    mata P= S*invsym(quadcross(S,S))*S&#39;

    *first 2sls
    if &amp;quot;`fixed&#39;&amp;quot;!=&amp;quot;&amp;quot; mata theta_1= invsym(X_1&#39;*P*X_1)*X_1&#39;*P*(Id-G1)*y
    else mata theta_1= invsym(X_1&#39;*P*X_1)*X_1&#39;*P*y
    
    *building instrument
    if &amp;quot;`fixed&#39;&amp;quot;!=&amp;quot;&amp;quot; {
        mata Z = G1*luinv(Id-theta_1[1]*G1)*(Id-G1)*(X*theta_1[2::(1+cols(X))] +  G1*X*theta_1[(2+cols(X))::(1+2*cols(X))] ), (Id-G1)*X, (Id-G1)*G1*X   
    }
    else{
        mata Z = J(rows(X),1,1), G1*luinv(Id-theta_1[2]*G1)*( theta_1[1]*J(rows(X),1,1) + X*theta_1[3::(2+cols(X))] +  G1*X*theta_1[(3+cols(X))::(2+2*cols(X))] ), X, G1*X
    }
    *
    
    *final 2sls
    if &amp;quot;`fixed&#39;&amp;quot;!=&amp;quot;&amp;quot; mata theta = luinv(quadcross(Z,X_1))*quadcross(Z,(Id-G1)*y)
    else mata theta = luinv(quadcross(Z,X_1))*quadcross(Z,y)

    *resids
    if &amp;quot;`fixed&#39;&amp;quot;!=&amp;quot;&amp;quot; {
        mata e= (Id-G1)*y - luinv(Id-theta[1]*G1)*((Id-G1)*X*theta[2::(1+cols(X))] + (Id-G1)*G1*X*theta[(2+cols(X))::(1+2*cols(X))] )
    }
    else{
        mata e= y - luinv(Id-theta[2]*G1)*( theta[1]*J(rows(X),1,1) + X*theta[3::(2+cols(X))] +  G1*X*theta[(3+cols(X))::(2+2*cols(X))] )
    }


    *variance
    mata V = luinv(quadcross(Z,X_1))*(Z&#39;)*diag(e:^2)*Z*luinv(quadcross(X_1,Z))
}

*sending results to Stata
mata st_matrix(&amp;quot;b&amp;quot;,theta&#39;)
mata st_matrix(&amp;quot;V&amp;quot;,V)

*row and col names for matrices
local exog_peer //list for names of exogenous effects
foreach var in `varlist&#39;{
    local exog_peer `exog_peer&#39; `var&#39;_p
}
if &amp;quot;`fixed&#39;&amp;quot;!=&amp;quot;&amp;quot; {
    local varnames `dep&#39;_p `varlist&#39; `exog_peer&#39;
}
else{
    local varnames _cons `dep&#39;_p `varlist&#39; `exog_peer&#39;
}


*adding col and rownames
matrix colnames b= `varnames&#39;
matrix colnames V = `varnames&#39;
matrix rownames V = `varnames&#39;
}
*storing eclass results
ereturn post b V, depname(`dep&#39;) esample(muestra)
mata st_numscalar(&amp;quot;e(N)&amp;quot;, rows(G1))
mata st_numscalar(&amp;quot;e(df_r)&amp;quot;, rows(X_1)-cols(X_1))
eret local cmd peer_iv
ereturn display

restore     
end

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;example&#34;&gt;Example&lt;/h2&gt;
&lt;p&gt;Here we will run a little example to see how the command works, and how you can generate an adjacency matrix in Stata. We are going to use the &lt;code&gt;auto&lt;/code&gt; dataset with 1978 automobile data, and we are going to create a random adjacency matrix &lt;code&gt;G&lt;/code&gt; with elements that are drawn from a uniform between 0 an 1, but we will force the elements in the main diagonal to be 0. We are also going to row normalize the adjacency matrix.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;%%stata

sysuse auto, clear

*generating the matrix
mata G= runiform(`c(N)&#39;, `c(N)&#39;) 
forval i=1/`c(N)&#39;{
    mata G[strtoreal(st_local(&amp;quot;i&amp;quot;)),strtoreal(st_local(&amp;quot;i&amp;quot;))]=0
}

*running the regression
peer_iv price trunk turn, row adj(G)

eret list
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;. 
. sysuse auto, clear
(1978 automobile data)

. 
. *generating the matrix
. mata G= runiform(`c(N)&#39;, `c(N)&#39;) 

. forval i=1/`c(N)&#39;{
  2.         mata G[strtoreal(st_local(&amp;quot;i&amp;quot;)),strtoreal(st_local(&amp;quot;i&amp;quot;))]=0
  3. }

. 
. *running the regression
. peer_iv price trunk turn, row adj(G)
------------------------------------------------------------------------------
       price | Coefficient  Std. err.      t    P&amp;gt;|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
       _cons |   41706.23   48765.18     0.86   0.395    -55603.18    139015.6
     price_p |  -1.527064   11.64602    -0.13   0.896    -24.76633     21.7122
       trunk |   141.5504   83.60055     1.69   0.095    -25.27191    308.3727
        turn |    98.8758   103.6205     0.95   0.343    -107.8956    305.6472
     trunk_p |     439.69   968.8704     0.45   0.651    -1493.661    2373.041
      turn_p |  -959.4334   2872.551    -0.33   0.739    -6691.519    4772.652
------------------------------------------------------------------------------

. 
. eret list

scalars:
                  e(N) =  74
               e(df_r) =  68

macros:
                e(cmd) : &amp;quot;peer_iv&amp;quot;
         e(properties) : &amp;quot;b V&amp;quot;
             e(depvar) : &amp;quot;price&amp;quot;

matrices:
                  e(b) :  1 x 6
                  e(V) :  6 x 6

. 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see the output of the regression, including a constant, the coefficient &lt;code&gt;price_p&lt;/code&gt; is the coefficient of the endogenous effect, while &lt;code&gt;trunk_p&lt;/code&gt; and &lt;code&gt;turn_p&lt;/code&gt; are the exogenous effects.&lt;/p&gt;
&lt;p&gt;After the regression command we ran the &lt;code&gt;eret list&lt;/code&gt; command, and we can see all the elements that are stored after running the command.&lt;/p&gt;
&lt;h2 id=&#34;storing-mata-matrices&#34;&gt;Storing Mata matrices&lt;/h2&gt;
&lt;p&gt;At least for my particular application, computing the adjacency matrix was very slow, so it is not something that I would do each time before I want to run peer effects regressions. To avoid this, we can use the &lt;code&gt;Mata&lt;/code&gt; functions &lt;code&gt;matsave&lt;/code&gt; and &lt;code&gt;matuse&lt;/code&gt; to store a matrix as a &lt;code&gt;.mmat&lt;/code&gt; object, and then load it into Stata.&lt;/p&gt;
&lt;h1 id=&#34;checking-if-the-code-works&#34;&gt;Checking if the code works&lt;/h1&gt;
&lt;p&gt;Here, to see if my code works properly, I will run the &lt;code&gt;R&lt;/code&gt; code provided by Bramoullé, Djebbari and Fortin (it can be found &lt;a href=&#34;https://rpubs.com/Nicolas_Gallo/549370&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;) to generate data, then estimate peer effects with and without fixed effects, export their data to Stata, and then see if my function obtains the same coefficients.&lt;/p&gt;
&lt;p&gt;The code provided by the authors is meant to be used to run Monte Carlo simulations, so I made some modifications to keep only the relevant parts. Also, for both cases, the authors defined different data generating processes, so we will have 2 vectors of dependent variables, but all of them are generated with the vector of white noise.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#Python package to use magic R commands
%load_ext rpy2.ipython
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;generating-network-data-in-r&#34;&gt;Generating network data in R&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;%%R

library(knitr)
library(igraph)
library(truncnorm)
set.seed(1)

alpha=0.7683
beta=0.4666
gamma=0.0834
delta=0.1507
e_var=0.1
#Generating a graph with 100 vertices and a probability of link of 0.04 with the &amp;quot;random.renyi.game()&amp;quot; function
g&amp;lt;-erdos.renyi.game(100,0.04)
#Generating the associated weighted adjacency matrix
G&amp;lt;-get.adjacency(g)
G&amp;lt;-as.matrix(G)

#Drawing a vector x of characteristics
x_sim&amp;lt;-matrix(rbinom(n = nrow(G),size = 1,prob = 0.9458 ),nrow(G),1)
for(i in 1:nrow(x_sim)){
  if(x_sim[i,] != 0){
    x_sim[i,]&amp;lt;-rtruncnorm(n = 1,a = 0,b = 1000,mean = 1,sd = 3) 
  }
}
#a vector filled with 1,  size m x 1 (used when there is an intercept in the model, i.e. when fixed_effects = FALSE)
l&amp;lt;-matrix(1,nrow(G),1)

GX&amp;lt;-G %*% x_sim
G2X&amp;lt;-(G %*% G) %*% x_sim
#an identity matrix of appropriate size
I&amp;lt;-(diag(nrow(G))) 
# Inv corresponds to (I - Beta*G))^(-1)   in the reduced form(check equation (5))
# Solve function gives the inverse of a matrix
Inv&amp;lt;-solve(I - beta * G)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;case-without-fixed-effects&#34;&gt;Case without fixed effects&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;%%R

#the instrument vector of size m x 4
S&amp;lt;-matrix(c(l,x_sim,GX,G2X),nrow(x_sim),)

#P is the weighting matrix of size m x n
P&amp;lt;-S %*% solve(t(S) %*% S) %*% t(S)


eps&amp;lt;-matrix(rnorm(n = nrow(G),mean = 0,sd = e_var),nrow(G),1)
y&amp;lt;-alpha * Inv %*% l  + Inv %*% (gamma * I + delta * G) %*% x_sim  + Inv %*% eps
Gy&amp;lt;-G %*% y

#X tilde, size n x 4
X_t&amp;lt;-matrix(c(l,Gy,x_sim,GX),nrow(x_sim),)

#theta 2sls and extracting its parameters
th_2sls &amp;lt;-solve(t(X_t) %*% P %*% X_t) %*% t(X_t) %*% P %*% y
alpha_2sls&amp;lt;-th_2sls[1]
beta_2sls&amp;lt;-th_2sls[2]
gamma_2sls&amp;lt;-th_2sls[3]
delta_2sls&amp;lt;-th_2sls[4]

#Recalculate I with Beta_2sls
I_2sls&amp;lt;-solve((diag(nrow(G)) - beta_2sls * G ))  

#Gy estimated in theta 2sls
gy_2sls&amp;lt;- G %*% I_2sls %*% (alpha_2sls * l   + gamma_2sls * x_sim + GX * delta_2sls)

Z_th&amp;lt;-matrix(c(rep(1,nrow(G)),gy_2sls,x_sim,GX),nrow(x_sim),)

#THETAS
#theta lee
th_lee_1&amp;lt;-solve(t(Z_th) %*% X_t) %*% t(Z_th) %*% y
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;case-with-fixed-effects&#34;&gt;Case with fixed effects&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;%%R
IG &amp;lt;-(I - G)
#the instrument vector of size m x 3
S&amp;lt;-matrix(c(IG%*%x_sim,IG%*%GX,IG%*%G2X),nrow(G),)

#P is the weighting matrix of size m x m
P&amp;lt;-S %*% solve(t(S) %*% S) %*% t(S)

y2&amp;lt;- solve(IG) %*% Inv %*% (gamma*I + delta * G) %*% IG %*% x_sim + solve(IG) %*% Inv %*% IG %*% eps

#X tilde, size m x 3
X_t&amp;lt;-matrix(c(G%*%IG%*%y2 ,IG%*%x_sim,IG%*%GX),nrow(x_sim),)


#theta 2sls and extracting its parameters
th_2sls &amp;lt;-solve(t(X_t) %*% P %*% X_t) %*% t(X_t) %*% P %*% IG%*%y2
beta_2sls&amp;lt;-th_2sls[1]
gamma_2sls&amp;lt;-th_2sls[2]
delta_2sls&amp;lt;-th_2sls[3]

#Recalculate I with Beta_2sls
Inv_2sls&amp;lt;-solve(I - beta_2sls * G )
#IGy estimated in theta 2sls
IGy_2sls&amp;lt;-Inv_2sls %*% (gamma_2sls * I + delta_2sls * G) %*% IG %*% x_sim + Inv_2sls %*% IG %*% eps 

IG_Gy_2sls&amp;lt;- G %*% Inv_2sls %*% (IG %*% (x_sim * gamma_2sls + GX* delta_2sls))

Z_th&amp;lt;-matrix(c(IG_Gy_2sls,IG%*%x_sim,IG%*%GX),nrow(G),)


#THETAS
#theta lee
th_lee_2&amp;lt;-solve(t(Z_th) %*% X_t) %*% t(Z_th) %*% IG%*%y2
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;storing-data-in-r-as-csv-and-reading-it-in-stata&#34;&gt;Storing data in R as CSV, and reading it in Stata&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;%%R
#storing data and adjacency matrix as CSV, to be readed in Stata later
write.csv(data.frame(x_sim,y,y2),&#39;data.csv&#39;,row.names = FALSE)
write.csv(G,&#39;adjacency.csv&#39;,row.names = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%stata
*reading adjacency matrix, and passing it to Mata
import delimited &amp;quot;adjacency.csv&amp;quot;, clear
putmata  G_r=(v*), replace

*reading data
import delimited &amp;quot;data.csv&amp;quot;, varnames(1) clear
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;. *reading adjacency matrix, and passing it to Mata
. import delimited &amp;quot;adjacency.csv&amp;quot;, clear
(encoding automatically selected: ISO-8859-2)
(100 vars, 100 obs)

. putmata  G_r=(v*), replace
(1 matrix posted)

. 
. *reading data
. import delimited &amp;quot;data.csv&amp;quot;, varnames(1) clear
(encoding automatically selected: ISO-8859-1)
(3 vars, 100 obs)

. 
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;comparing-results-without-fixed-effects&#34;&gt;Comparing results without fixed effects&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%stata
peer_iv y x_sim, adj(G_r)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;-----------------------------------------------------------------------------
&amp;gt; -
           y | Coefficient  Std. err.      t    P&amp;gt;|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
       _cons |   .7693815   .0861937     8.93   0.000     .5982885    .9404746
         y_p |   .4668116   .0019521   239.13   0.000     .4629367    .4706865
       x_sim |   .0832526   .0174479     4.77   0.000     .0486188    .1178864
     x_sim_p |   .1501907   .0057371    26.18   0.000     .1388026    .1615789
------------------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;%%R
th_lee_1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;          [,1]
[1,] 0.7693815
[2,] 0.4668116
[3,] 0.0832526
[4,] 0.1501907
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;comparing-results-with-fixed-effects&#34;&gt;Comparing results with fixed effects&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%stata
peer_iv y2 x_sim, fixed adj(G_r)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;------------------------------------------------------------------------------
          y2 | Coefficient  Std. err.      t    P&amp;gt;|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
        y2_p |   .4663327   .0025075   185.97   0.000      .461356    .4713095
       x_sim |   .0841561   .0081916    10.27   0.000      .067898    .1004143
     x_sim_p |   .1500943   .0018714    80.20   0.000       .14638    .1538086
------------------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;%%R
th_lee_2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;           [,1]
[1,] 0.46633273
[2,] 0.08415615
[3,] 0.15009431
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, in both cases, the &lt;code&gt;peer_iv&lt;/code&gt; command produces the same estimates as the original package. Furthermore, both packages produce estimates that are very similar to the ones used to generate our data (for instance, we have that $\beta=0.4666$, and in both cases we get coefficients very close to that).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tutorial: Landsat-8 image download and visualization using Google Earth Engine and Python</title>
      <link>https://nicolas-suarez.github.io/blog/landsat-8/</link>
      <pubDate>Mon, 24 May 2021 00:00:00 +0000</pubDate>
      <guid>https://nicolas-suarez.github.io/blog/landsat-8/</guid>
      <description>&lt;p&gt;In this tutorial I want to explain how to download and visualize Landsat-8 images using GEE and Python packages. I wrote this code originally for my &lt;a href=&#34;https://github.com/nicolas-suarez/urban_emissions/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Using satellite and street level images to predict urban emissions&amp;rdquo;&lt;/a&gt; project,  and I&amp;rsquo;m sharing it here because we struggled to download images in a simple and beginner friendly way. You can find the actual Jupyter notebook with this example and the proper outputs in &lt;a href=&#34;https://github.com/nicolas-suarez/landsat_8_tutorial/blob/main/landsat_8_tutorial_download.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this link&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;initial-set-up&#34;&gt;Initial set-up&lt;/h2&gt;
&lt;p&gt;We start by importing some packages. Besides installing the packages, we also need a Google-Earth Engine account to use the &lt;code&gt;ee&lt;/code&gt; package.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os
import numpy as np
import pandas as pd
import pickle
import time
import math
import requests, zipfile, io
from geetools import cloud_mask
from IPython.display import Image

#importing Earth Engine packages
import ee #install in the console with &amp;quot;pip install earthengine-api --upgrade&amp;quot;
ee.Authenticate()  #every person needs an Earth Engine account to do this part
ee.Initialize()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;defining-satellite-images&#34;&gt;Defining satellite images&lt;/h2&gt;
&lt;p&gt;Here we are going to define our satellite images. In this example, we are going to use the Landsat-8 Surfarce reflectance Tier 1 image collection, containing all the images taken during 2020, and using the 3 RGB  bands for this example.&lt;/p&gt;
&lt;p&gt;Here we are also going to apply a mask to the pixels with the &lt;code&gt;cloud_mask&lt;/code&gt; function from the &lt;a href=&#34;https://pypi.org/project/geetools/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;geetools package&lt;/a&gt;. The mask allow us to exclude from our collection all the pixels that were covered by clouds, snow or similar sources of interference from an image. Since we are working for the moment with an image collection, we use the &lt;code&gt;map()&lt;/code&gt; function to individually apply the mask to all the elements in the collection.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#defining image
startDate = &#39;2020-01-01&#39;
endDate = &#39;2020-12-31&#39;
landsat = ee.ImageCollection(&amp;quot;LANDSAT/LC08/C01/T1_SR&amp;quot;)
# filter date
landsat = landsat.filterDate(startDate, endDate) 
#applying cloud masking
landsat_masked=landsat.map( cloud_mask.landsatSR([&#39;cloud&#39;]) )
#selecting bands
landsat_masked=landsat_masked.select([&amp;quot;B2&amp;quot;,&amp;quot;B3&amp;quot;,&amp;quot;B4&amp;quot;])
landsat = landsat.select([&amp;quot;B2&amp;quot;,&amp;quot;B3&amp;quot;,&amp;quot;B4&amp;quot;])
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;function-to-define-task-or-downloading-image-directly&#34;&gt;Function to define task or downloading image directly&lt;/h2&gt;
&lt;p&gt;After doing this, I&amp;rsquo;m going to define a function to download imagery called &lt;code&gt;image_task&lt;/code&gt;. This function download satellite images centered around a point defined by latitude and longitude coordinates, with a certain size, and allows us to store them either on a Google Drive folder, Google Cloud bucket or locally.&lt;/p&gt;
&lt;p&gt;We start by defining &lt;code&gt;len&lt;/code&gt;, the total size of the image in meters, that is computed as the product of the resolution of our Landsat-8 SR images (30 meters) and the number of pixels we want to capture in the image. After that, we generate a circle around the point of interested, using as the radius half of our &lt;code&gt;len&lt;/code&gt; parameter, and then we put a bounding box around the circle to get a square. We extract the coordinates of the bounding box and pass them to a &lt;code&gt;ee.Geometry.Rectangle&lt;/code&gt; object called &lt;code&gt;rectangle&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;After that, we only need to crop our &lt;code&gt;rectangle&lt;/code&gt; object from our satellite image, called &lt;code&gt;image&lt;/code&gt; here. Here, our image is going to be our previously defined &lt;code&gt;ee.ImageCollection&lt;/code&gt; object containing our &lt;code&gt;Landstat-8 SR&lt;/code&gt; satellite images. We are going to clip our &lt;code&gt;rectangle&lt;/code&gt; area using the &lt;code&gt;filterBounds()&lt;/code&gt; method, and then we use the &lt;code&gt;mean()&lt;/code&gt; function to obtain a mean-composite of the images in the &lt;code&gt;ImageCollection&lt;/code&gt; for the specified area. We also need to define the &lt;code&gt;region&lt;/code&gt; where we are working (which is essentially the same as our &lt;code&gt;rectangle&lt;/code&gt;), and the dimensions of our image (the number of pixels for the width and height).&lt;/p&gt;
&lt;p&gt;Finally, the last step depends on how we want to download our images:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If we want to work locally with our files, then we are going to generate a download URL for our image in TIFF format, with the &lt;code&gt;ee.Image.getDownloadURL()&lt;/code&gt; method. We then use &lt;code&gt;requests&lt;/code&gt;, &lt;code&gt;zipfile&lt;/code&gt; and &lt;code&gt;io&lt;/code&gt; to download the image as a ZIP file, decompress it and store it a local folder.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If we want to work with cloud services, like Google Drive or Google Cloud, which is more reliable when we work with large volumes of images, then we are going to use &lt;code&gt;ee.batch.Export.image.toCloudStorage()&lt;/code&gt; or &lt;code&gt;ee.batch.Export.image.toDrive()&lt;/code&gt; to create a Google Earth engine &lt;code&gt;task&lt;/code&gt; with specifications of what kind of image we want, and then we use &lt;code&gt;task.start()&lt;/code&gt; to start the task, and the images are going to appear in the specified cloud folders. We can also check the status of the task to see if the images were downloaded succesfully or not.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def image_download(image,point,image_res,n_pixels,folder_name, image_name, storage=&amp;quot;local&amp;quot;):
    
    &amp;quot;&amp;quot;&amp;quot;
    Function to download satellite images from a ee.imageCollection object.
    We first generate a bounding box of image_res*n_pixels meters around &amp;quot;point&amp;quot;,
    then we clip that region from the image collection, take the mean image from the collection,
    and send that as a task to the Google Earth Engine. 
    After that, we download the image Google Cloud Storage if storage==&amp;quot;Cloud&amp;quot;, 
    to Google Drive if storage==&amp;quot;Drive&amp;quot; or to a local folder if storage==&amp;quot;local&amp;quot;.
    
    Inputs:
    -image= ee.ImageCollection object
    -point= ee.Geometry.Point object
    -image_res= resolution of the image in meters
    -n_pixels= number of pixels to extract on the images
    -storage= string indicating if we are storing the images in Google Cloud,Google Drive or locally.
              Defaults to local storage.
    -folder_name= string with Google Cloud bucket name if storage==&amp;quot;Cloud&amp;quot;
                  string with the name of a folder in the root of Google Drive if storage==&amp;quot;Drive&amp;quot;
                  string with the path to the image if storage==&amp;quot;local&amp;quot;
    -image_name= string with the image_name for the TIFF image.

    Output:
     When storage==&amp;quot;Cloud&amp;quot; or storage==&amp;quot;Drive&amp;quot;:
     -task= an EE task object. we can then use task.status() to check the status of the task.
     If the task is completed, we will see a TIFF image in &amp;quot;folder_name&amp;quot; with name &amp;quot;image_name.tif&amp;quot;.
     The image has 3 dimensions, where the first 2 are n_pixels, and the 3rd is the number of bands of &amp;quot;image&amp;quot;.
     When storage==&amp;quot;local&amp;quot;:
     -there is no output, but we will see one TIFF file per band of our image in the folder &amp;quot;folder_name&amp;quot;.
    &amp;quot;&amp;quot;&amp;quot;
    #generating the box around the point
    len=image_res*n_pixels # for landsat, 30 meters * 224 pixels
    region= point.buffer(len/2).bounds().getInfo()[&#39;coordinates&#39;]
    #defining the rectangle
    coords=np.array(region)
    #taking min and maxs of coordinates to define the rectangle
    coords=[np.min(coords[:,:,0]), np.min(coords[:,:,1]), np.max(coords[:,:,0]), np.max(coords[:,:,1])]
    rectangle=ee.Geometry.Rectangle(coords)

    if storage==&amp;quot;Cloud&amp;quot;:
        #generating the export task (dimensions is &amp;quot;WIDTHxHEIGHT&amp;quot;)
        task=ee.batch.Export.image.toCloudStorage(image=image.filterBounds(rectangle).mean(), 
                            bucket=folder_name, 
                            description=image_name, 
                            region=str(region), dimensions=str(n_pixels)+&amp;quot;x&amp;quot;+str(n_pixels))
        #starting the task
        task.start()
        return task
    
    if storage==&amp;quot;Drive&amp;quot;:
        #generating the export task (dimensions is &amp;quot;WIDTHxHEIGHT&amp;quot;)
        task=ee.batch.Export.image.toDrive(image=image.filterBounds(rectangle).mean(), 
                            folder=folder_name, 
                            description=image_name, 
                            region=str(region), dimensions=str(n_pixels)+&amp;quot;x&amp;quot;+str(n_pixels))
        #starting the task
        task.start()
        return task
    
    if storage==&amp;quot;local&amp;quot;:
        #downloading the image
        r=requests.get( image.filterBounds(rectangle).mean().getDownloadURL({
                            &#39;name&#39;: image_name, 
                            &#39;region&#39;: str(region),
                            &#39;dimensions&#39;: str(n_pixels)+&amp;quot;x&amp;quot;+str(n_pixels)}))
        #unzip it to the selected directory
        z = zipfile.ZipFile(io.BytesIO(r.content))
        z.extractall(folder_name)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;testing-our-function&#34;&gt;Testing our function&lt;/h2&gt;
&lt;p&gt;To test how our function works, we are going to create a little example, taking a 6.72 by 6.72 km satellite image around the Oval in Stanford campus, and storing it locally:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#defining the oval as a point
oval=ee.Geometry.Point(-122.169678,37.429154)

#running our function
image_download(image=landsat,point=oval,image_res=30,n_pixels=224,folder_name=&#39;LS8_images&#39;, image_name=&#39;test_image&#39;, storage=&amp;quot;local&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we are going to test that the images were indeed downloaded to the &lt;code&gt;LS8_images&lt;/code&gt; folder:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;os.listdir(&#39;LS8_images&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We indeed see that there are 3 files in our folder, one for each channel of the image.&lt;/p&gt;
&lt;p&gt;We could further work with this images. For instance, we can use packages like imageio to read the images in Python, read them into a numpy array and then use numpy functions like stack to stack all individual images into one big array.&lt;/p&gt;
&lt;h1 id=&#34;visualizing-images&#34;&gt;Visualizing images&lt;/h1&gt;
&lt;p&gt;To visualize images, we are going to do very similar things to what we did before. I will generate the satellite images in almost the same way I did before, but now we are going to add some visualization parameters, &lt;code&gt;visParams&lt;/code&gt; to properly see our images.&lt;/p&gt;
&lt;p&gt;We are going to obtain a &lt;code&gt;jpg&lt;/code&gt; image using the &lt;code&gt;ee.Image.getThumbUrl()&lt;/code&gt;function, and we are going to visualize directly here. The function programmed below allow us to decide if we want to see a cloud masked version of the image or the regular one.&lt;/p&gt;
&lt;p&gt;The visualization parameters and the image size are defined here, but could be modified if we wanted.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#defining parameters for the function
image_res=30
n_pixels=224

#visualization parameters
visParams={&#39;min&#39;: 0, &#39;max&#39;: 3000, &#39;gamma&#39;: 1.4,  
           &#39;bands&#39; : [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;], &#39;dimensions&#39; : str(n_pixels)+&amp;quot;x&amp;quot;+str(n_pixels),
           &#39;format&#39; : &#39;jpg&#39;}

#defining the function
def visualization(point,name,mask=True):
    &#39;&#39;&#39;
    Function to visualize the images for our ML application.
    Inputs:
        -point= ee.Geometry.point object
        -name: name that is going to be given to the jpg file
        -mask: True to get masked image, False to get unmasked image
    Outputs:
        The function doesn&#39;t produce an output, but generates a file called
        &amp;quot;name.jpg&amp;quot; in the current directory
    &#39;&#39;&#39;
    #computing bounding box
    len=image_res*n_pixels # for landsat, 30 meters * 224 pixels
    region= point.buffer(len/2).bounds().getInfo()[&#39;coordinates&#39;]
    coords=np.array(region)
    coords=[np.min(coords[:,:,0]), np.min(coords[:,:,1]), np.max(coords[:,:,0]), np.max(coords[:,:,1])]
    rectangle=ee.Geometry.Rectangle(coords)
    
    #clipping the area from satellite image
    if mask==True:
        clipped_image= landsat_masked.mean().clip(rectangle)
    else:
        clipped_image= landsat.mean().clip(rectangle)
        
    #getting the image
    requests.get(clipped_image.getThumbUrl(visParams))
    open(name+&#39;.jpg&#39;, &#39;wb&#39;).write(requests.get(clipped_image.getThumbUrl(visParams)).content)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we are going to test the code. First we will visualize our image around the Oval without cloud masking:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;visualization(point=oval,name=&#39;oval_no_mask&#39;,mask=False)
Image(filename=&#39;oval_no_mask.jpg&#39;) 
&lt;/code&gt;&lt;/pre&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/landsat-8/oval_no_mask_hu925074f9182ffee7a618036463d8005d_25765_5888580dcdc71f8b2894e2d5b1a59c54.jpg 400w,
               /blog/landsat-8/oval_no_mask_hu925074f9182ffee7a618036463d8005d_25765_d06e44af9b5eaa2d32149c1a2ffddf0d.jpg 760w,
               /blog/landsat-8/oval_no_mask_hu925074f9182ffee7a618036463d8005d_25765_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://nicolas-suarez.github.io/blog/landsat-8/oval_no_mask_hu925074f9182ffee7a618036463d8005d_25765_5888580dcdc71f8b2894e2d5b1a59c54.jpg&#34;
               width=&#34;224&#34;
               height=&#34;224&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;And now we are going to visualize our image applying cloud masking:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;visualization(point=oval,name=&#39;oval_cloud_masking&#39;,mask=True)
Image(filename=&#39;oval_cloud_masking.jpg&#39;) 
&lt;/code&gt;&lt;/pre&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /blog/landsat-8/oval_cloud_masking_huef47ff7ed2b8cadf0a63b1ff93a97438_31059_3b79d85081fe32d71f43bd7be89ebbc0.jpg 400w,
               /blog/landsat-8/oval_cloud_masking_huef47ff7ed2b8cadf0a63b1ff93a97438_31059_8a60a6f13e6d14e1db8b0de00a75b557.jpg 760w,
               /blog/landsat-8/oval_cloud_masking_huef47ff7ed2b8cadf0a63b1ff93a97438_31059_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://nicolas-suarez.github.io/blog/landsat-8/oval_cloud_masking_huef47ff7ed2b8cadf0a63b1ff93a97438_31059_3b79d85081fe32d71f43bd7be89ebbc0.jpg&#34;
               width=&#34;224&#34;
               height=&#34;224&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>A little Stata command to export tables to Excel</title>
      <link>https://nicolas-suarez.github.io/blog/stata-tables/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://nicolas-suarez.github.io/blog/stata-tables/</guid>
      <description>&lt;p&gt;I usually prefer to work in LaTeX, but from time to time I&amp;rsquo;m forced to share my results in Excel. In Stata, I used to use the &lt;a href=&#34;http://repec.org/bocode/o/outreg2.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Outreg2 command&lt;/a&gt;, but the output generated by this program has a weird format, and you always have to read some error messages in Excel.&lt;/p&gt;
&lt;p&gt;Because of this, I decided to program a little piece of code to easily export my regression results to Excel. I&amp;rsquo;m not very creative, so I called my custom command &lt;strong&gt;export_tables&lt;/strong&gt;. You can find the code at my &lt;a href=&#34;https://github.com/nicolas-suarez/Stata-table_export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Github page&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;syntax&#34;&gt;Syntax&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;export_tables, Models(string) Dec(real) Cell(string) USING(string) SHEET(string) [ Options ]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Models() contains a list of the models you estimated, and saved with the &amp;ldquo;Estimates Store&amp;rdquo; command.&lt;/li&gt;
&lt;li&gt;Dec() indicates the number of decimal places of your model&amp;rsquo;s coefficients.&lt;/li&gt;
&lt;li&gt;Cell() indicates in which Excel&amp;rsquo;s cell the table is going to begin.&lt;/li&gt;
&lt;li&gt;Using() indicates where are you going to save the excel document, and Sheet() indicates how the sheet of the document will be named.&lt;/li&gt;
&lt;li&gt;In options, you can use Keep() to keep the coefficients associated with certain variables, Drop() to drop the coefficients associated with some variables, Stats() to report some e() statistics stored in your models and Dstats() helps you to set the number of decimal places associated with these statistics. Variables prints the name of the variables in your table, and label prints the variables&#39; labels instead. Std to display standard errors below the coefficients, Pvalues to display the p-values of the coefficients below them, and See to print your output in the console as a table.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-to-use-the-command&#34;&gt;How to use the command&lt;/h2&gt;
&lt;p&gt;The idea behind the command is to run your regressions, store the results with estimates store, and then export the results to excel. You will get a table without a header, but you will see in every row the name of the variable, the coefficients of each model (with stars representing the significance level), the standard errors, and at the end, some statitics. After running this command, you can use &lt;a href=&#34;https://www.stata.com/manuals13/pputexcel.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;putexcel&lt;/a&gt; to further modify your spreadsheet, adding headers, bold or italic text, borders, etc.&lt;/p&gt;
&lt;p&gt;For the moment, this command only works with regression commands like &lt;strong&gt;reg&lt;/strong&gt;, &lt;strong&gt;probit&lt;/strong&gt;, &lt;strong&gt;ivreg2&lt;/strong&gt; or others, but doesn&amp;rsquo;t work with commands like &lt;strong&gt;heckman&lt;/strong&gt; or others that display the results of 2 or more estimations at the same time.&lt;/p&gt;
&lt;h2 id=&#34;example&#34;&gt;Example&lt;/h2&gt;
&lt;p&gt;You can run the following example code:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;sysuse auto

reg mpg rep78 trunk
est sto m1

reg turn length gear_ratio rep78
est sto m2

export_tables, models(m1 m2) dec(2) cell(A1) using(&amp;quot;test.xlsx&amp;quot;) sheet(&amp;quot;sheet1&amp;quot;) stats(&amp;quot;N r2_a&amp;quot;) label std see
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You could also use a wilcard in the models, and write something like &lt;code&gt;models(m*)&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
